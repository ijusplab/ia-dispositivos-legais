{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cmlima_preprocessamento.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LqhTAWis30XZ","colab_type":"text"},"source":["# Carregar/Atualizar Parâmetros"]},{"cell_type":"markdown","metadata":{"id":"pnZRzNhx40R1","colab_type":"text"},"source":["Após preencher os dados de configuração e executar a célula, os dados das abas `subsituicao_simples` e `substituicao_regex` da planilha ficarão armazenados nas variáveis `df_simples` e `df_regex` no formato de `DataFrames` do `pandas`."]},{"cell_type":"code","metadata":{"id":"f6zYeJE8npk7","colab_type":"code","cellView":"form","outputId":"c8ee4026-e9de-4a70-90d5-ca819ea80741","executionInfo":{"status":"ok","timestamp":1578561440825,"user_tz":180,"elapsed":7116,"user":{"displayName":"Caio Moysés de Lima","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCXbyoQwQAM29J_JbLMH6Q7lVeIgBBgKNPdd4CXrQ=s64","userId":"08207008988418593310"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#@title Configuração do Projeto\n","PROJECT_PATH = \"/LIIA-3R/PROJETOS/ia-dispositivos-legais\" #@param {type:\"string\"}\n","PARAMS_PATH = \"/params\" #@param {type:\"string\"}\n","SPREADSHEET_NAME = \"cmlima_substituicoes.xlsx\" #@param {type:\"string\"}\n","USER_NAME = \"cmlima\" #@param {type:\"string\"}\n","\n","from google.colab import drive\n","import pandas as pd\n","\n","ROOT = '/content/drive/My\\ Drive'\n","WORKING_PATH = ROOT + PROJECT_PATH + PARAMS_PATH\n","\n","def path_exists(path):\n","  output = !test -e {path} && echo 1 || echo 0\n","  return output[0] == '1'\n","\n","def file_exists(path):\n","  output = !(ls {path} >> /dev/null 2>&1 && echo 1) || echo 0\n","  return output[0] == '1'\n","\n","def mount_drive():\n","  if not path_exists(ROOT):\n","    print('integrando Google Drive ao ambiente...')\n","    drive.mount('/content/drive')\n","    print()\n","\n","def read_excel(file, sheet_name):\n","  if not file_exists(file):\n","    raise Exception('Planilha não localizada.')\n","  return pd.read_excel(file, sheet_name=sheet_name)\n","\n","mount_drive()\n","%cd {WORKING_PATH}\n","df_replace = read_excel(SPREADSHEET_NAME, 'replace')\n","df_replace = df_replace.fillna('')\n","df_replace = df_replace.replace(to_replace=r'^\\\"|\\\"$', value='', regex=True)\n","df_replace = df_replace.replace({'is_literal': 1.0}, True)\n","df_replace = df_replace.replace({'is_literal': ''}, False)\n","df_stop_words = read_excel(SPREADSHEET_NAME, 'stop_words')\n","df_stop_words = df_stop_words.fillna('')\n","df_stop_words = df_stop_words.replace(to_replace=r'^\\\"|\\\"$', value='', regex=True)\n","print('Script concluído.')\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/LIIA-3R/PROJETOS/ia-dispositivos-legais/params\n","Script concluído.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nBzIXt5S6Dll","colab_type":"text"},"source":["# Exibir DataFrames em Formato HTML"]},{"cell_type":"code","metadata":{"id":"FKl7wQkoy6He","colab_type":"code","colab":{},"cellView":"form"},"source":["#@title Para exibir, execute a célula\n","from IPython.display import display, HTML\n","\n","def render_as_table(name, pandas_data_frame):\n","  print('\\n' + name + ':')\n","  display(HTML(pandas_data_frame.to_html()))\n","\n","render_as_table('replace', df_replace)\n","render_as_table('stop_words', df_stop_words)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CX3Vw8bh6YXo","colab_type":"text"},"source":["# Exibir DataFrames em Formato JSON"]},{"cell_type":"code","metadata":{"id":"NR_2jJyowVVW","colab_type":"code","colab":{},"cellView":"form"},"source":["#@title Para exibir, execute a célula\n","import json\n","\n","def render_as_json(name, pandas_data_frame):\n","  print('\\n' + name + ':')\n","  parsed = json.loads(pandas_data_frame.to_json(orient='records'))\n","  print(json.dumps(parsed, ensure_ascii=False, indent=4))\n","\n","render_as_json('replace', df_replace)\n","render_as_json('stop_words', df_stop_words)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gP-CfbN5BYMo","colab_type":"text"},"source":["# Salvar DataFrames em Formato JSON"]},{"cell_type":"code","metadata":{"id":"HOeuAl6kBf_P","colab_type":"code","colab":{},"cellView":"form"},"source":["#@title Para salvar, execute a célula\n","def save_as_json(file_name, pandas_data_frame):\n","  with open(file_name, 'w') as file:\n","    file.write(pandas_data_frame.to_json(force_ascii=False, orient='records'))\n","\n","%cd {WORKING_PATH}\n","save_as_json(USER_NAME + '_replace.json', df_replace)\n","save_as_json(USER_NAME + '_stop_words.json', df_stop_words)\n","print('Script concluído.')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wUzOmsdfNu_V","colab_type":"text"},"source":["# Processar Substituições"]},{"cell_type":"code","metadata":{"id":"7xsceWxGOO9m","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Configuração { vertical-output: false }\n","ALGORITHM_TYPE = \"all\" #@param [\"all\", \"literal_only\", \"regex_only\", \"all_literal_first\", \"all_regex_first\"]\n","INPUT_PATH = \"/input\" #@param {type:\"string\"}\n","INPUT_FILE = \"\" #@param {type:\"string\"}\n","OUTPUT_PATH = \"/output\" #@param {type:\"string\"}\n","OUTPUT_TO_FILE = True #@param {type:\"boolean\"}\n","\n","!pip install PyPDF2\n","!pip install python-docx\n","\n","import json, re, os, PyPDF2, docx\n","from google.colab import files\n","from IPython.display import clear_output\n","\n","clear_output()\n","\n","def stop_words_algorithm(text_input, params):\n","  for item in params:\n","    text_input = text_input.replace(item['search_expression'], item['replace_by'])\n","  return text_input\n","\n","def replace_algorithm(text_input, params, algorithm_type):\n","  for item in params:\n","    if item['is_literal'] and ('all' in algorithm_type or 'literal' in algorithm_type):\n","      text_input = text_input.replace(item['search_expression'], item['replace_by'])\n","    if not item['is_literal'] and ('all' in algorithm_type or 'regex' in algorithm_type):\n","      text_input = re.sub(item['search_expression'], item['replace_by'], text_input, count=0, flags=0)\n","  return text_input\n","\n","def split_paragraphs(text_input):\n","  return [ para + '.' for para in re.split('[.!?](?![0-9])', text_input) ]\n","\n","def paragraphs_to_text(paragraphs):\n","  return '\\n--------------------------------------------------------------------------------------------\\n'.join(paragraphs)\n","\n","def print_in_shell(paragraphs):\n","  print(paragraphs_to_text(paragraphs))\n","\n","def print_to_file(file_name, paragraphs):\n","  with open(file_name, 'w') as file:\n","    file.write(paragraphs_to_text(paragraphs))\n","\n","def get_text_from_pdf(file_name):\n","  pdfFileObj = open(file_name, 'rb')\n","  pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n","  content = []\n","  for num in range(pdfReader.numPages):\n","    page = pdfReader.getPage(num)\n","    try:\n","      text = page.extractText()\n","    except:\n","      text = ''\n","    content.append(text)\n","  return ''.join(content)\n","\n","def get_text_from_docx(file_name):\n","  doc = docx.Document(file_name)\n","  content = []\n","  for para in doc.paragraphs:\n","    content.append(para.text)\n","  return '\\n'.join(content)\n","\n","def get_text_from_txt(file_name):\n","  with open(file_name, 'r') as file:\n","    content = file.read()\n","  return content\n","\n","def get_text_from_file(file_name):\n","  if re.match('^.+\\.(pdf)$', file_name):\n","    return get_text_from_pdf(file_name)\n","  if re.match('^.+\\.(docx)$', file_name):\n","    return get_text_from_docx(file_name)\n","  if re.match('^.+\\.(txt)$', file_name):\n","    return get_text_from_txt(file_name)\n","  raise Exception('Arquivo inválido.')\n","\n","def get_text_from_files():\n","  contents = []\n","  for file_name in os.listdir():\n","    if re.match('^.+\\.(txt|docx|pdf)$', file_name):\n","      info = {\n","          'name': file_name,\n","          'content': get_text_from_file(file_name)\n","      }\n","      contents.append(info)\n","  return contents\n","\n","def file_name_without_extension(file_name):\n","  return re.match('(.+?)(\\.[^.]*$|$)', file_name).group(1)\n","\n","def process_text(raw_text, file_name, algorithm_type):\n","  stop_words_params = json.loads(df_stop_words.to_json(force_ascii=False, orient='records'))\n","  replace_params = json.loads(df_replace.to_json(force_ascii=False, orient='records'))\n","  if algorithm_type == 'all_literal_first':\n","    replace_params = sorted(replace_params, key=lambda item: item['is_literal'], reverse=True)\n","  if algorithm_type == 'all_regex_first':\n","    replace_params = sorted(replace_params, key=lambda item: item['is_literal'], reverse=False)\n","  print(json.dumps(replace_params, ensure_ascii=False, indent=4))\n","\n","  new_name = file_name_without_extension(file_name) + '.txt'\n","  text = stop_words_algorithm(raw_text, stop_words_params)\n","  text = replace_algorithm(text, replace_params, algorithm_type)\n","\n","  paragraphs = split_paragraphs(text)\n","\n","  if OUTPUT_TO_FILE:\n","    print_to_file(new_name, paragraphs)\n","  else:\n","    print_in_shell(paragraphs)\n","  \n","\n","# # #\n","\n","\n","DATA_PATH = ROOT + PROJECT_PATH + INPUT_PATH\n","RESULTS_PATH = ROOT + PROJECT_PATH + OUTPUT_PATH\n","\n","%cd {DATA_PATH}\n","\n","if len(INPUT_FILE) > 0:\n","  raw_text = get_text_from_file(INPUT_FILE)\n","  %cd {RESULTS_PATH}\n","  process_text(raw_text, INPUT_FILE, ALGORITHM_TYPE)\n","  print('arquivo ' + INPUT_FILE + ' processado.')\n","else:\n","  items = get_text_from_files()\n","  %cd {RESULTS_PATH}\n","  for item in items:\n","    process_text(item['content'], item['name'], ALGORITHM_TYPE)\n","    print('arquivo ' + item['name'] + ' processado.')\n","\n","%cd {WORKING_PATH}\n","\n","print('Script concluído.')"],"execution_count":0,"outputs":[]}]}